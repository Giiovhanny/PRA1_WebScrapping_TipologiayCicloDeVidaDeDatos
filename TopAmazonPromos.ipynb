{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd06097b842ea50001c3bff7ee79878899cb75817ad0771f8215d32734ca32d1c05",
   "display_name": "Python 3.9.4 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "6097b842ea50001c3bff7ee79878899cb75817ad0771f8215d32734ca32d1c05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Primero se cargan las librerías que se van a usar"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import whois\n",
    "import builtwith"
   ]
  },
  {
   "source": [
    "Ahora se define la función para obtener el robots.txt"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obt_robot(siteurl):\n",
    "    if siteurl.endswith('/'):\n",
    "        path=siteurl\n",
    "    else:\n",
    "        path=siteurl+'/'\n",
    "    req=requests.get(path+'robots.txt',data=None)\n",
    "    return req.text"
   ]
  },
  {
   "source": [
    "Ahora vamos a guardar el sitio web de amazon para posteriormente obtener los datos del robtos.txt"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web = obt_robot('https://www.amazon.com/')"
   ]
  },
  {
   "source": [
    "Obtenemos ahora el robots.txt e imprimimos el resultado"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_robots = re.sub( r'<[^>]*>', ' ', text).strip()\n",
    "print(data_robots)"
   ]
  },
  {
   "source": [
    "Como se aprecia en el archivo robots.txt, este nos muestra los apartados dentro del sito web para los cuales no deberíamos acceder con nuestro proceso de extracción de datos y que se respetarán a lo largo del proyecto"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Ahora se va a identificar las tecnologías presentes detras del sitio web de Amazon"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_used = builtwith.parse('https://www.amazon.com/')\n",
    "print(tech_used)"
   ]
  },
  {
   "source": [
    "Luego se van a buscar mas datos sobre el sitio web"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whois.whois('amazon.com/')"
   ]
  },
  {
   "source": [
    "Para realizar la busqueda de datos, primero usamos la librería HTMLSessions para transformar la estructuta de los datos y creamos una lista vacía para que posteriomente se puedan agregar las variables capturadas "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_de_descuentos = []\n",
    "x = HTMLSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obt_analisis = argparse.ArgumentParser(description='Busqueda de productos y promociones en Amazon')\n",
    "obt_analisis.add_argument('buscar', metavar='buscar', type=str, help='Por favor escriba el producto que desea buscar. Si esta compuesto por mas de una palabra usar + para generar el espaciado a las palabras')\n",
    "entrada = obt_analisis.parse_args()"
   ]
  },
  {
   "source": [
    "Ahora se va a empezar a trabajar en función de realizar la extracción de datos del sitio web. Para este proyecto vamos a realizar las busqueda de promociones para una marca de computadores, sin embargo,  si es necesario se puede cambiar el item de busqueda."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "url = f'https://www.amazon.com/s?k={buscar}'"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "Con la primera función que se va a crear se podrán acceder a la data del sitio web. Luego usamos sleep para evitar el bloqueo del servidor y posteriormente se le hace parseo al sitio por medio de la librería BeatifulSoup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datos(url):\n",
    "    y = x.get(url)\n",
    "    y.html.render(sleep=5)\n",
    "    soup = BeautifulSoup(y.html.html, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "source": [
    "El siguiente paso consiste en crear la función que nos arroje la lista de los datos especificos que queremos del producto(título, título abreviado, link, precio actual en el caso si es que tiene descuento, precio sin descuento, críticas, calificación, si es un producto promocionado por amazon a través de amazon choice y la fecha de extracción de los datos)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descuentos(soup):\n",
    "# Se crea productos para almacenar allí la data temporal para el bucle\n",
    "    productos = soup.find_all('div', {'data-component-type':'s-search-result'})\n",
    "    amazonChoice=False\n",
    "    for item in productos:\n",
    "        # Busqueda del nombre completo del producto\n",
    "        titulo = item.find('a', {'class': 'a-link-normal a-text-normal'}).text.replace(',',' ').strip()\n",
    "        # Busqueda de amazon choice\n",
    "        try:\n",
    "            amazonChoice = item.find('span', {'class': 'a-badge-text', 'data-a-badge-color':'sx-cloud'})\n",
    "        except:\n",
    "            amazonChoise= False\n",
    "        # Abreviación del título para mejorar comprensión\n",
    "        titulo_abreviado = item.find('a', {'class': 'a-link-normal a-text-normal'}).text.replace(',',' ').strip()[:20]\n",
    "        # Busqueda del link del producto\n",
    "        link = item.find('a', {'class': 'a-link-normal a-text-normal'})['href']\n",
    "        # Se crea primero una lista llamada lista?spam para verificar si el producto tiene o no descuento\n",
    "        lista_span = item.find_all('span', {'class': 'a-offscreen'})\n",
    "        precio_actual, precio_sin_descuento = 0, 0\n",
    "        if not lista_span:\n",
    "            print(titulo, \"No matches\")\n",
    "        else:\n",
    "            try:\n",
    "                precio_actual = float(lista_span[0].text.replace('$','').replace(',','').strip())\n",
    "                precio_sin_descuento = float(lista_span[1].text.replace('$','').replace(',','').strip())\n",
    "            except:\n",
    "                precio_sin_descuento = float(lista_span[0].text.replace('$','').replace(',','').strip())\n",
    "        # Busqueda de Críticas del producto\n",
    "        try:\n",
    "            #criticas = item.find('span', {'class': \"a-size-base\"}, partial=False).text.strip()\n",
    "            criticas = float(item.find(lambda tag: tag.name == 'span' and tag.get('class') == ['a-size-base']).text.strip())\n",
    "        except:\n",
    "            criticas = 0\n",
    "        # Busqueda de la calificación en estrellas del producto\n",
    "        try:\n",
    "            calificacion = float(item.find('span', {'class': 'a-declarative'}).text.replace(' out of 5 stars','').strip())\n",
    "        except:\n",
    "            calificacion = 0\n",
    "        # Fecha en la cuál fue extraída la información\n",
    "        date = datetime.datetime.now()\n",
    "        if(amazonChoice):\n",
    "                 amazonChoice=True\n",
    "        else:\n",
    "            amazonChoice=False\n",
    "        # Creación de la lista con las varibales obtenidas para cada producto\n",
    "        articulo_en_venta= {\n",
    "            'titulo': titulo,\n",
    "            'titulo_abreviado': titulo_abreviado,\n",
    "            'link': link,\n",
    "            'precio_actual': precio_actual,\n",
    "            'precio_sin_descuento': precio_sin_descuento,\n",
    "            'criticas': criticas,\n",
    "            'calificacion': calificacion,  \n",
    "            'AmazonChoice': amazonChoice,\n",
    "            'Date':  str(date.day)+'/'+str(date.month)+'/'+str(date.year)    \n",
    "            }\n",
    "        lista_de_descuentos.append(articulo_en_venta)\n",
    "    return\n"
   ]
  },
  {
   "source": [
    "Posteriormente se crea la función para realizar el salto de página dentro del sitio web de amazon"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def siguiente_pagina(soup): \n",
    "    # Se realiza la busqueda de las páginas que contienen el producto\n",
    "    pages = soup.find('ul', {'class': 'a-pagination'})\n",
    "    # Condicional para continuar la busqueda hasta que encuentre la página final\n",
    "    if not pages.find('li', {'class': 'a-disabled a-last'}):\n",
    "        url = 'https://www.amazon.com' + str(pages.find('li', {'class': 'a-last'}).find('a')['href'])\n",
    "        return url\n",
    "    else:\n",
    "        return\n",
    "# Condición para realizar la busqueda en la primeras 20 páginas\n",
    "i=0\n",
    "while i<20:\n",
    "    soup = datos(url)\n",
    "    descuentos(soup)\n",
    "    url = siguiente_pagina(soup)\n",
    "    i=i+1\n",
    "    if not url:\n",
    "        break\n",
    "    else:\n",
    "        print(url)\n",
    "        print(len(lista_de_descuentos))"
   ]
  },
  {
   "source": [
    "Creamos una funcón para generar el dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(lista_de_descuentos)"
   ]
  },
  {
   "source": [
    "Se calcula el porcentaje de descuento del producto y se ordena de mayor a menor"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['porcentaje_de_descuento'] = 100 - ((df.precio_actual / df.precio_sin_descuento) * 100)\n",
    "df = df.sort_values(by=['porcentaje_de_descuento'], ascending=False)"
   ]
  },
  {
   "source": [
    "Se crea el archivo csv a partir de la información obtenida y se emite un mensaje de finalización de la ejecución del programa"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(buscar + 'descuentos_encontrados_giovanny333.csv', index=False)\n",
    "print('La busqueda de ' + buscar + ' ha finalizado')"
   ]
  }
 ]
}